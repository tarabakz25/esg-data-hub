/**
 * OpenAI Hybrid Client
 * GPT-4o-mini for text analysis + embedding model for vector generation
 */
import { OpenAI } from 'openai';

export class OpenAIEmbeddingClient {
  private client: OpenAI;
  private embeddingModel: string;
  private textModel: string;
  
  constructor() {
    if (!process.env.OPENAI_API_KEY) {
      throw new Error('OPENAI_API_KEY environment variable is required');
    }
    
    this.client = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
    });
    
    // åŸ‹ã‚è¾¼ã¿ç”Ÿæˆç”¨ãƒ¢ãƒ‡ãƒ«
    this.embeddingModel = "text-embedding-ada-002";
    // ãƒ†ã‚­ã‚¹ãƒˆåˆ†æç”¨ãƒ¢ãƒ‡ãƒ«
    this.textModel = "gpt-4o-mini-2024-07-18";
  }

  /**
   * GPT-4o-miniã‚’ä½¿ç”¨ã—ã¦KPIãƒãƒƒãƒ”ãƒ³ã‚°ã®ãƒ’ãƒ³ãƒˆã‚’ç”Ÿæˆ
   */
  async analyzeKPIMapping(text: string, availableKPIs: string[]): Promise<{
    suggestedKPI: string | null;
    confidence: number;
    reasoning: string;
  }> {
    try {
      const prompt = `
ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†æã—ã¦ã€æœ€ã‚‚é©åˆ‡ãªESG KPIã‚’ç‰¹å®šã—ã¦ãã ã•ã„ã€‚

åˆ†æå¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆ: "${text}"

åˆ©ç”¨å¯èƒ½ãªKPIé¸æŠè‚¢:
${availableKPIs.map(kpi => `- ${kpi}`).join('\n')}

ä»¥ä¸‹ã®å½¢å¼ã§JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š
{
  "suggestedKPI": "æœ€é©ãªKPIåï¼ˆè©²å½“ãªã—ã®å ´åˆã¯nullï¼‰",
  "confidence": 0.0-1.0ã®ä¿¡é ¼åº¦,
  "reasoning": "é¸æŠç†ç”±ã®ç°¡æ½”ãªèª¬æ˜"
}
`;

      const response = await this.client.chat.completions.create({
        model: this.textModel,
        messages: [
          {
            role: "system",
            content: "ã‚ãªãŸã¯ESGï¼ˆç’°å¢ƒãƒ»ç¤¾ä¼šãƒ»ã‚¬ãƒãƒŠãƒ³ã‚¹ï¼‰ãƒ‡ãƒ¼ã‚¿åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ESG KPIã‚’æ­£ç¢ºã«è­˜åˆ¥ã™ã‚‹èƒ½åŠ›ãŒã‚ã‚Šã¾ã™ã€‚"
          },
          {
            role: "user", 
            content: prompt
          }
        ],
        temperature: 0.1,
        max_tokens: 500
      });

      const responseText = response.choices[0]?.message?.content;
      if (!responseText) {
        throw new Error('No response from GPT-4o-mini');
      }

      // JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹
      const result = JSON.parse(responseText);
      return {
        suggestedKPI: result.suggestedKPI,
        confidence: result.confidence,
        reasoning: result.reasoning
      };

    } catch (error) {
      console.error('GPT-4o-mini analysis failed:', error);
      return {
        suggestedKPI: null,
        confidence: 0,
        reasoning: "åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ"
      };
    }
  }

  async generateEmbedding(text: string): Promise<number[]> {
    try {
      const response = await this.client.embeddings.create({
        model: this.embeddingModel,
        input: text,
      });
      
      if (!response.data || response.data.length === 0) {
        throw new Error('Invalid embedding response from OpenAI');
      }
      
      return response.data[0].embedding;
    } catch (error) {
      console.error('OpenAI embedding generation failed:', error);
      
      // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: MockEmbeddingClientã‚’ä½¿ç”¨
      console.log('ğŸ”„ Falling back to MockEmbeddingClient');
      const mockClient = new MockEmbeddingClient();
      return await mockClient.generateEmbedding(text);
    }
  }

  async generateBatchEmbeddings(texts: string[]): Promise<number[][]> {
    try {
      const response = await this.retryWithBackoff(() => 
        this.client.embeddings.create({
          model: this.embeddingModel,
          input: texts,
        })
      );
      
      return response.data.map(item => item.embedding);
    } catch (error) {
      console.warn('Batch embedding failed, falling back to mock client:', error);
      
      // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: MockEmbeddingClientã‚’ä½¿ç”¨
      const mockClient = new MockEmbeddingClient();
      return await mockClient.generateBatchEmbeddings(texts);
    }
  }

  private async retryWithBackoff<T>(
    fn: () => Promise<T>,
    maxRetries = 3,
    baseDelay = 1000
  ): Promise<T> {
    for (let i = 0; i < maxRetries; i++) {
      try {
        return await fn();
      } catch (error) {
        if (i === maxRetries - 1) throw error;
        
        // ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ã‚ˆã‚Šé•·ãå¾…æ©Ÿ
        const isRateLimit = error instanceof Error && 
          (error.message.includes('quota') || error.message.includes('rate') || error.message.includes('429'));
        const delay = isRateLimit ? baseDelay * Math.pow(3, i) : baseDelay * Math.pow(2, i);
        
        console.warn(`OpenAI API retry ${i + 1}/${maxRetries} after ${delay}ms. Error:`, error);
        await new Promise(resolve => setTimeout(resolve, delay));
      }
    }
    throw new Error('Max retries exceeded');
  }

  // é¡ä¼¼åº¦è¨ˆç®—ç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
  static cosineSimilarity(a: number[], b: number[]): number {
    const dotProduct = a.reduce((sum, val, i) => sum + val * b[i], 0);
    const magnitudeA = Math.sqrt(a.reduce((sum, val) => sum + val * val, 0));
    const magnitudeB = Math.sqrt(b.reduce((sum, val) => sum + val * val, 0));
    return dotProduct / (magnitudeA * magnitudeB);
  }
}

/**
 * ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ¢ãƒƒã‚¯EmbeddingClient
 * OpenAI APIã®ä»£ã‚ã‚Šã«æ–‡å­—åˆ—ãƒãƒƒãƒãƒ³ã‚°ãƒ™ãƒ¼ã‚¹ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—
 */
export class MockEmbeddingClient {
  private readonly EMBEDDING_SIZE = 1536; // OpenAI text-embedding-ada-002ã¨åŒã˜1536æ¬¡å…ƒ

  /**
   * KPIã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°
   */
  private readonly KPI_KEYWORDS = {
    'GHG_EMISSIONS': ['æ¸©å®¤åŠ¹æœã‚¬ã‚¹', 'ghg', 'emission', 'co2', 'carbon', 'æ’å‡º', 'ã‚«ãƒ¼ãƒœãƒ³'],
    'ENERGY_USAGE': ['ã‚¨ãƒãƒ«ã‚®ãƒ¼', 'energy', 'é›»åŠ›', 'ä½¿ç”¨é‡', 'consumption', 'kwh', 'mwh'],
    'WATER_USAGE': ['æ°´', 'water', 'æ°´ä½¿ç”¨', 'ç”¨æ°´', 'm3', 'ãƒªãƒƒãƒˆãƒ«', 'liter'],
    'WASTE_AMOUNT': ['å»ƒæ£„ç‰©', 'waste', 'ã‚´ãƒŸ', 'garbage', 'disposal', 'å‡¦åˆ†'],
    'EMPLOYEE_COUNT': ['å¾“æ¥­å“¡', 'employee', 'ç¤¾å“¡', 'äººæ•°', 'count', 'staff', 'worker'],
    'FEMALE_MGMT_RATIO': ['å¥³æ€§', 'female', 'ç®¡ç†è·', 'management', 'æ¯”ç‡', 'ratio', 'mgmt'],
    'SAFETY_INCIDENTS': ['å®‰å…¨', 'safety', 'äº‹æ•…', 'incident', 'ç½å®³', 'accident'],
    'TRAINING_HOURS': ['ç ”ä¿®', 'training', 'æ•™è‚²', 'education', 'æ™‚é–“', 'hours', 'å­¦ç¿’'],
    'BOARD_MEETINGS': ['å–ç· å½¹', 'board', 'ä¼šè­°', 'meeting', 'å½¹å“¡', 'director'],
    'COMPLIANCE_RATE': ['ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹', 'compliance', 'æ³•ä»¤', 'éµå®ˆ', 'ç‡', 'rate']
  };

  async generateEmbedding(text: string): Promise<number[]> {
    // ãƒ†ã‚­ã‚¹ãƒˆã‚’æ­£è¦åŒ–
    const normalizedText = text.toLowerCase();
    
    // å„KPIã¨ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—
    const kpiScores = Object.entries(this.KPI_KEYWORDS).map(([kpiId, keywords]) => {
      let score = 0;
      
      // ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°
      keywords.forEach(keyword => {
        if (normalizedText.includes(keyword.toLowerCase())) {
          score += 1;
        }
      });
      
      // éƒ¨åˆ†ãƒãƒƒãƒãƒ³ã‚°ã«ã‚‚ã‚¹ã‚³ã‚¢ã‚’ä¸ãˆã‚‹
      keywords.forEach(keyword => {
        const similarity = this.calculateStringSimilarity(normalizedText, keyword.toLowerCase());
        if (similarity > 0.7) {
          score += similarity * 0.5;
        }
      });
      
      return { kpiId, score };
    });

    // æœ€é«˜ã‚¹ã‚³ã‚¢ã®KPIã‚’ç‰¹å®š
    const maxScore = Math.max(...kpiScores.map(s => s.score));
    const bestMatch = kpiScores.find(s => s.score === maxScore);

    // ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆï¼ˆ1536æ¬¡å…ƒï¼‰
    const embedding = new Array(this.EMBEDDING_SIZE).fill(0);
    
    if (bestMatch && bestMatch.score > 0) {
      // æœ€é©ãƒãƒƒãƒã®KPIã«åŸºã¥ã„ã¦ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆ
      const kpiIndex = Object.keys(this.KPI_KEYWORDS).indexOf(bestMatch.kpiId);
      const baseValue = 0.8 + (bestMatch.score * 0.2); // 0.8-1.0ã®ç¯„å›²
      
      // ç‰¹å®šã®æ¬¡å…ƒã«é«˜ã„å€¤ã‚’è¨­å®šï¼ˆ1536æ¬¡å…ƒã«å¯¾å¿œï¼‰
      const segmentSize = Math.floor(this.EMBEDDING_SIZE / Object.keys(this.KPI_KEYWORDS).length);
      for (let i = 0; i < segmentSize; i++) {
        embedding[kpiIndex * segmentSize + i] = baseValue + (Math.random() * 0.1 - 0.05);
      }
      
      // ãã®ä»–ã®æ¬¡å…ƒã«ãƒã‚¤ã‚ºã‚’è¿½åŠ 
      for (let i = 0; i < this.EMBEDDING_SIZE; i++) {
        if (embedding[i] === 0) {
          embedding[i] = Math.random() * 0.3;
        }
      }
    } else {
      // ãƒãƒƒãƒã—ãªã„å ´åˆã¯ãƒ©ãƒ³ãƒ€ãƒ ãªä½ã„å€¤
      for (let i = 0; i < this.EMBEDDING_SIZE; i++) {
        embedding[i] = Math.random() * 0.4;
      }
    }

    return embedding;
  }

  async generateBatchEmbeddings(texts: string[]): Promise<number[][]> {
    const promises = texts.map(text => this.generateEmbedding(text));
    return Promise.all(promises);
  }

  /**
   * æ–‡å­—åˆ—é¡ä¼¼åº¦è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰
   */
  private calculateStringSimilarity(str1: string, str2: string): number {
    const longer = str1.length > str2.length ? str1 : str2;
    const shorter = str1.length > str2.length ? str2 : str1;
    
    if (longer.length === 0) return 1.0;
    
    const editDistance = this.levenshteinDistance(longer, shorter);
    return (longer.length - editDistance) / longer.length;
  }

  /**
   * ãƒ¬ãƒ¼ãƒ™ãƒ³ã‚·ãƒ¥ã‚¿ã‚¤ãƒ³è·é›¢è¨ˆç®—
   */
  private levenshteinDistance(str1: string, str2: string): number {
    const matrix = [];
    
    for (let i = 0; i <= str2.length; i++) {
      matrix[i] = [i];
    }
    
    for (let j = 0; j <= str1.length; j++) {
      matrix[0][j] = j;
    }
    
    for (let i = 1; i <= str2.length; i++) {
      for (let j = 1; j <= str1.length; j++) {
        if (str2.charAt(i - 1) === str1.charAt(j - 1)) {
          matrix[i][j] = matrix[i - 1][j - 1];
        } else {
          matrix[i][j] = Math.min(
            matrix[i - 1][j - 1] + 1,
            matrix[i][j - 1] + 1,
            matrix[i - 1][j] + 1
          );
        }
      }
    }
    
    return matrix[str2.length][str1.length];
  }

  // é¡ä¼¼åº¦è¨ˆç®—ç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
  static cosineSimilarity(a: number[], b: number[]): number {
    const dotProduct = a.reduce((sum, val, i) => sum + val * b[i], 0);
    const magnitudeA = Math.sqrt(a.reduce((sum, val) => sum + val * val, 0));
    const magnitudeB = Math.sqrt(b.reduce((sum, val) => sum + val * val, 0));
    return dotProduct / (magnitudeA * magnitudeB);
  }
} 